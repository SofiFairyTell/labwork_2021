# Интеллектуальные модели объектов и систем

Принципиальным отличием данного класса моделей от традиционных математических обекто моделей и систем является то, что интеллектуальная модель является не формальной математической копией моделируемого объекта с сохранением или без сохранения его внутреннего содержания, а по сути представляет осмысленнную интеллктуальную имитацию поведения реального объекта. 

Среди современных процессов, объектов и систем найдется немало таких которые обладают комплексом неожиданных для классических методов математического моделирования качеств. 

"Неудобным" или "слабоструктурированным" или "плохоопредлеенным" объектом присущи такие свойства: 
- Уникальность
- Отсуствие формалируземой цели существования и оптимальности 
- Нестационарность структуры и параметров
- Неполнота или практически полное отсутствие формального описания объектов

_Стационарный параметр изменяется в пределах определенного значения. Если иное - но параметр нестационарный_

Существенное повышение эффективности методов моделирования сложных объектов заключается в создании интеллектуальных моделей способных в той или иной степени воспроизводить определенные интеллектуальные действия человека, связанные с приобретением, анализом, классификацией знаний в той или иной предметной области. 

Таким образом интеллектуальные модели объектов и систем представляют собой математическую интерпертацию мыслительной деятельности человека, связанной с мысленным представлением исследователем связей и закономерностей поведения моделируемой системы. 

Данный класс моделей базируется на методах искусственного интеллекта: 
- Нейронных сетях
- Системах нечеткого вывода
- Генетических алгоритмах
- Эскпертных системах и т.д.

## Нейросетевые модели

Длительный период эволюции придал мозгу человека много качеств, которые отсутствуют как в машинах с архитектурой Фон-Неймана, так и в современных параллельных компьютерах. 

К ним относятся: 
- массовый параллелизм
- распределенное представление информации и вычисления
- спообность к обучению и обобщению 
- адаптивность 
- свойство котекстуальной обработки информации 
- торентность к ошибкам 
- низкое энергопотребление

### Проблемы решаемые с помощью нейронных сетей

1. Классификация образов 
   > Задача состоит в указании принадлежности входного образа(изображения, речевого сигнала), представленного вектором признаков одному или нескольким предварительно определенным классам
2. Кластеризация 
3. Аппроксимация функции
4. Предсказание (прогноз) 
5. Оптимизация 
    > Нахождение такого решения, которое удовлетворяет системе ограничений и максизирует или минизирует значение функции. 
6. Управление

Нейрон представляет из себя элемент который вычисляет выходной сигнал(по определенному правилу) из совокупности входных сигналов.

Основная последовательность действиий:
- прием сигналов от предыдущих элементов сети
- комбинирование входных сигналов 
- вычисление выходного сигнала 
- передача сигнала всем элементам нейронной сети.

Между собой нейроны могут быть соединены абсолютно по разному. Это определяется структурой нейронной сети. Чаще всего структура связи между нейронами представляется в виде матрицы W, которую называют весовой матрицей. 

Элементы матрицы wij определяют вес связи идущей от элемента i к j.
 

# Функции активации элемента

Рассмотрим выходные сигналы для каждого элемента сети имеется определенное правило в соответствии с которым из значения комбинированного ввода элемента вычисляется его выходное значение - это правило __функция активации__, а само значние - активность нейрона. 

В роли функции активации могут выступать абсолютно любые математические функции. 

Пример: 
- Пороговая функция, если значение комбинированного ввода ниже определенного значения(порога), то активность равна 0. Если выше - 1. 

см. слайд 2 презентации [Схемы](https://github.com/SofiFairyTell/labwork_2021/blob/f8fd85a38d58c375844a49537ca698e513cc25f7/Моделирование систем_/Лекции/Схемы.pptx): а, б - пороговые функции

# Определение нейрона

По входным каналам на нейрон поступают данные задачи, а на выходе формируется результат работы. Нейрон вычисляет взвешенную сумму выходных сигналов , а затем преобразует сумму с помощью нелинейной функции. __То есть взвешенная сумма передается функции активации__

см. слайд 3 презентации [Схемы](https://github.com/SofiFairyTell/labwork_2021/blob/f8fd85a38d58c375844a49537ca698e513cc25f7/Моделирование систем_/Лекции/Схемы.pptx): вместо порога нейрона указать смещение. 

Принцип: Берем значение нейрона, вес - вычисляем сумму. Результат на выход нейрона. 

Рассмотрим пример: 
[Пример_нейроныXOR](https://github.com/SofiFairyTell/labwork_2021/blob/e26dbcbf7120583b17e11fd0ab88dd616232ff2d/Моделирование систем_/Лекции/Пример_лекция4.png)
Задача примера заключается в том, что при помощи нейроной сети вычислить операцию XOR(исключающее или). На входы подаем комбинации 0 и 1. На выходе - операция XOR. 
Над стрелками - веса нейронов. 
1 и 2 входные элементы. Элемент 7 - выходной. Элементы 3 и 4 - элементы смещения. 
Нейроны 5 и 6 - скрытые, поскольку они не связаны с внешней средой. 
Таким образом получаем три слоя:
- Входной
- Скрытый 
- Выходной

Для вычисления комбинированного ввода в этой сети будем использовать правило суммирования взвешенных связей. 
В качестве функции активации будет выступать пороговая функция.
_Правила_ Если комбинированный ввод элемента меньше 0, то выход нейрона равен 0, иначе 1.  

Подадим на вход нейрона 1 - 1, а на вход нейрона 2 - 0. Рассчитаем выходное значение сети. 

Комбинированный ввод элемента 5 равен: Net5 = 1*(-1)+0*(-1)+1.5 = 0.5
_+1.5, потому что значение положительное_
Так как 0.5>0, то на выходе 1. 

Комбинированный ввод элемента 6 равен: Net5 = 1*(-1)+0*(-1)+0.5 = -0.5
Так как -0.5<0, то на выходе 0. 

Комбинированный ввод элемента 7 равен: Net7 = 1*(1)+0*(-1)-0.5 = 0.5
Так как 0.5>0, то на выходе 1.

Значит выходное значение сети это 1. 

Пример 2 см. слайд 6 презентации [Схемы](https://github.com/SofiFairyTell/labwork_2021/blob/f8fd85a38d58c375844a49537ca698e513cc25f7/Моделирование систем_/Лекции/Схемы.pptx):
Z - - скрытые нейроны
wij - 
X - то что на входе
t - то с чем на выходе сравнить. это обучающая выборка

xi - это нейрон выход
V - вес для основных нейронов
W - вес нейронов для скрытого слоя

Обучение сети включает в себя 3 стадии: 
1. Подача на входы сети обучающих данных
   1. > Каждый нейрон xi получает сигнал и широковещательно транслирует его каждому из скрытых нейронов 
   2. > Каждый срктый нейрон Z вычислает результат активационной функции и рассылает свой сигнал zj всем выходным нейронам
   3. > Каждый выходной нейрон Yk вычисляет результат своей активационной функции yk и это фактически может считаться выходом сети
   4. > В процессе обучения каждый нейрон на выходе сети сравнивает вычисленное значение yk предоставленным целевым значением tk из обучающей выборки и определяет соответствующее знаение ошибки для каждого входного шаблона. На основании этой ошибки вычисляется СИГМАk, которая используется при распространении ошибки от выходных нейронов до нейронов предыдущего, то есть скрытого слоя, а также при изменениии весов связей. После того как все СИГМА определены происходит одновременная корретировка весов всех связей. 
2. Обратное распространение ошибки
3. Коректировка весов

# Алгоритм
0. Инициализация весов и смещений
   > рекомн. случайные небольшие значения. выбор начальных весов оказывает влияние на то сумеет ли сеть достичь минимума ошибки и насколько быстро этот процесс будет происходить. 
1. До тех пор пока условие прекращения работы алгоритма неверно выполнять шаги с 2 по 9. 
   > Условие прекращение - достижение минимума величины ошибки. Обучающую выборку делят на несколько частей. 
2. Для каждой пары {Данные, Целевое значение} выполняются шаги с 3 по 8(распространение данных от входов к выходам). 
3. Каждый входной нейрон xi(i=1,2,3,4..n) отправляет полученный сигнал всем нейронам в следующем слое (скрытым)
4. Скрытый нейрон Zj (j = 1,2,3..p) суммирует взвешенные входящие сигналы по формуле выше, применяет активавационную функцию и передает результат следующему слою (выходному) (см слайд 11 презентации [Схемы](https://github.com/SofiFairyTell/labwork_2021/blob/f8fd85a38d58c375844a49537ca698e513cc25f7/Моделирование систем_/Лекции/Схемы.pptx):)
5. Каждый выходной нейрон yk сумминрует взвешеныне выходящие сигналы и применяетс Активационную функцию вычисляя выходной сигнал (слайд 12)
6. Каждый нейрон yk получает целевое значение и вычисляет ошибку. Вычисляется величина, на которую изменится вес связи. Параметр альфа характеризует скорость обучения. Каждый нейрон вычисляет сигма, смещение. После этого отправляет величину сигмаk предыдущему слою (обратное распространение ошибки)
7. Каждый скрытый нейон суммирует входящие ошибки от нейронов в последующем слое и вычисляет величину ошибки умножая полученное значение на полученное от активационной функции. После этого определяет на какую величину изменится вес связи и смещение. 
8. Изменение весов. Каждый выходной нейрон изменяет веса своих связей и каждый скрытый нейрон изменяет свои смещения и вес своих связей. Прибавляем величину корректировки, которые мы вычислили на предыдущем шаге. 
9. Проверка условия прекрашения работы алгоритма: возможны два варианта
   - Достижение суммарной квадратичной ошибкой результата на выходе сети предустановленного заранее минимума
   - Выполненеи определенного количества итераций алгоритма

В основе алгоритма лежит метод градиентного спуска. В зависимости от знака градиент функции (в данном случае значение функции это ошибка, а параметры это веса связей в сети) дает направление в котором значение функции возрастает стремительно. 

# Архитектуры

1. Perceptron - однослойная
2. Feed Forward - сеть прямого распространения. Не образуются циклы. Каждый нейрон одного слоя связан с каждым нейроном на следующем слое. Это полносвязные сети. Увеличение числа слоев делает из нее сеть прямого распространения. Применются для сжатия данных, распознования речи и т.д. 
3. Сеть Радиальных базисных функций. Архитектура аналогична 2. В качестве функции активации используется радиальная базисная функция. Радиальная - любая вещественная функция, значение которой зависит только от расстояния до начала координат или от расстояния от другой точки называемой центром. Чаще используется для задач Аппроксимации. 
4. Рекуррентные нейронные сети обладает реккуретыным состояние приобретенном при обработке предущим элементам последовательности. Например на основе предыдущих слов узнать следующее в предложении. Такие сети имеют внутренние циклы (петли). Поэтому такие сети эффективны для распознавания рукописного текста или речи. 
5. Двунаправленные рекуррентные сети
6. LSTM - при большом объеме данных обычные реккурентые нейронные сети становятся непригодными для использования. Так как запоминают последнюю пригодную ифнормацию и забывают об информации полученной давным давно. 
7. Сверточные нейронные сети. Для распознавания объектов, изображений. 
8. Генеративные состязательные сети. Умеют генерировать данные не отличимые от исходных. 

# Эволюциоонные модели

Сначала создается множество случайно сформированных объектов с заданной структурой - популяция объектов и функция, определяющая близость объектов к истинному решению, называемая функцией цены. 
Работают по общей схеме: 
1. Определяется цена объектов в популяция
2. С учетом цены и привнесении элемента случайности создаются объекты для популяции следующей итерации. 
3. Данный процесс повторяется либо до получения решения либо до окончания времени отведенного на решение. 
популяция имеет "память" - в ней накапливаются лучшие результаты предыдущих итераций и этим ЭМ отличаются от других методов случайного поиска. 
В создании нового объекта популяции обычно участвуют два существующих объекта от каждого из которых новый объект отбирает часть свойств. Это __скрещивание__ или __crossover__ . Объекты подвергаются мутации (случаное Изменение)
Иногда используется т.н. стратегия элитизма при которой несколько лучших особей переходят в следующее поколение без измений не участвуя в __crossover__  и отборе. 

Алгоритм состоит из шагов:
1. Задается структура объектов, функция цены и условие останова. 
2. Создается популяция объектов P. 
3. С помощью функции цены из P выбирается множество лучших объектов
4. Из выбранных объектов создаются новые - претенденты на попадание в следующую популяцию
5. Образование новой P из полученных на шаге 4 объектов
6. Из объектов выбирается тот что с большей ценой. Это и есть искомое решение. 

# Причины распространения эволюционных вычислений

1. Показали свою эффективность
2. Высокий параллелизм

# Сферы применения

1. Автомтизация  решения оптимизационных задач науки и техники, те которые для MAX и MIN ищут для некоторой целевой функции на множестве ограничений. 
2. Изучение и моделирование процессов естественной эволюции





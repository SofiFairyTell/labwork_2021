# Интеллектуальные модели объектов и систем

Принципиальным отличием данного класса моделей от традиционных математических обекто моделей и систем является то, что интеллектуальная модель является не формальной математической копией моделируемого объекта с сохранением или без сохранения его внутреннего содержания, а по сути представляет осмысленнную интеллктуальную имитацию поведения реального объекта. 

Среди современных процессов, объектов и систем найдется немало таких которые обладают комплексом неожиданных для классических методов математического моделирования качеств. 

"Неудобным" или "слабоструктурированным" или "плохоопредлеенным" объектом присущи такие свойства: 
- Уникальность
- Отсуствие формалируземой цели существования и оптимальности 
- Нестационарность структуры и параметров
- Неполнота или практически полное отсутствие формального описания объектов

_Стационарный параметр изменяется в пределах определенного значения. Если иное - но параметр нестационарный_

Существенное повышение эффективности методов моделирования сложных объектов заключается в создании интеллектуальных моделей способных в той или иной степени воспроизводить определенные интеллектуальные действия человека, связанные с приобретением, анализом, классификацией знаний в той или иной предметной области. 

Таким образом интеллектуальные модели объектов и систем представляют собой математическую интерпертацию мыслительной деятельности человека, связанной с мысленным представлением исследователем связей и закономерностей поведения моделируемой системы. 

Данный класс моделей базируется на методах искусственного интеллекта: 
- Нейронных сетях
- Системах нечеткого вывода
- Генетических алгоритмах
- Эскпертных системах и т.д.

## Нейросетевые модели

Длительный период эволюции придал мозгу человека много качеств, которые отсутствуют как в машинах с архитектурой Фон-Неймана, так и в современных параллельных компьютерах. 

К ним относятся: 
- массовый параллелизм
- распределенное представление информации и вычисления
- спообность к обучению и обобщению 
- адаптивность 
- свойство котекстуальной обработки информации 
- торентность к ошибкам 
- низкое энергопотребление

### Проблемы решаемые с помощью нейронных сетей

1. Классификация образов 
   > Задача состоит в указании принадлежности входного образа(изображения, речевого сигнала), представленного вектором признаков одному или нескольким предварительно определенным классам
2. Кластеризация 
3. Аппроксимация функции
4. Предсказание (прогноз) 
5. Оптимизация 
    > Нахождение такого решения, которое удовлетворяет системе ограничений и максизирует или минизирует значение функции. 
6. Управление

Нейрон представляет из себя элемент который вычисляет выходной сигнал(по определенному правилу) из совокупности входных сигналов.

Основная последовательность действиий:
- прием сигналов от предыдущих элементов сети
- комбинирование входных сигналов 
- вычисление выходного сигнала 
- передача сигнала всем элементам нейронной сети.

Между собой нейроны могут быть соединены абсолютно по разному. Это определяется структурой нейронной сети. Чаще всего структура связи между нейронами представляется в виде матрицы W, которую называют весовой матрицей. 

Элементы матрицы wij определяют вес связи идущей от элемента i к j.
 

# Функции активации элемента

Рассмотрим выходные сигналы для каждого элемента сети имеется определенное правило в соответствии с которым из значения комбинированного ввода элемента вычисляется его выходное значение - это правило __функция активации__, а само значние - активность нейрона. 

В роли функции активации могут выступать абсолютно любые математические функции. 

Пример: 
- Пороговая функция, если значение комбинированного ввода ниже определенного значения(порога), то активность равна 0. Если выше - 1. 

см. слайд 2 презентации [Схемы](https://github.com/SofiFairyTell/labwork_2021/blob/f8fd85a38d58c375844a49537ca698e513cc25f7/Моделирование систем_/Лекции/Схемы.pptx): а, б - пороговые функции

# Определение нейрона

По входным каналам на нейрон поступают данные задачи, а на выходе формируется результат работы. Нейрон вычисляет взвешенную сумму выходных сигналов , а затем преобразует сумму с помощью нелинейной функции. __То есть взвешенная сумма передается функции активации__

см. слайд 3 презентации [Схемы](https://github.com/SofiFairyTell/labwork_2021/blob/f8fd85a38d58c375844a49537ca698e513cc25f7/Моделирование систем_/Лекции/Схемы.pptx): вместо порога нейрона указать смещение. 

Принцип: Берем значение нейрона, вес - вычисляем сумму. Результат на выход нейрона. 

Рассмотрим пример: 
[Пример_нейроныXOR](https://github.com/SofiFairyTell/labwork_2021/blob/e26dbcbf7120583b17e11fd0ab88dd616232ff2d/Моделирование систем_/Лекции/Пример_лекция4.png)
Задача примера заключается в том, что при помощи нейроной сети вычислить операцию XOR(исключающее или). На входы подаем комбинации 0 и 1. На выходе - операция XOR. 
Над стрелками - веса нейронов. 
1 и 2 входные элементы. Элемент 7 - выходной. Элементы 3 и 4 - элементы смещения. 
Нейроны 5 и 6 - скрытые, поскольку они не связаны с внешней средой. 
Таким образом получаем три слоя:
- Входной
- Скрытый 
- Выходной

Для вычисления комбинированного ввода в этой сети будем использовать правило суммирования взвешенных связей. 
В качестве функции активации будет выступать пороговая функция.
_Правила_ Если комбинированный ввод элемента меньше 0, то выход нейрона равен 0, иначе 1.  

Подадим на вход нейрона 1 - 1, а на вход нейрона 2 - 0. Рассчитаем выходное значение сети. 

Комбинированный ввод элемента 5 равен: Net5 = 1*(-1)+0*(-1)+1.5 = 0.5
_+1.5, потому что значение положительное_
Так как 0.5>0, то на выходе 1. 

Комбинированный ввод элемента 6 равен: Net5 = 1*(-1)+0*(-1)+0.5 = -0.5
Так как -0.5<0, то на выходе 0. 

Комбинированный ввод элемента 7 равен: Net7 = 1*(1)+0*(-1)-0.5 = 0.5
Так как 0.5>0, то на выходе 1.

Значит выходное значение сети это 1. 

Пример 2 см. слайд 6 презентации [Схемы](https://github.com/SofiFairyTell/labwork_2021/blob/f8fd85a38d58c375844a49537ca698e513cc25f7/Моделирование систем_/Лекции/Схемы.pptx):
Z - - скрытые нейроны
wij - 
X - то что на входе
t - то с чем на выходе сравнить. это обучающая выборка

xi - это нейрон выход
V - вес для основных нейронов
W - вес нейронов для скрытого слоя

Обучение сети включает в себя 3 стадии: 
1. Подача на входы сети обучающих данных
   1. > Каждый нейрон xi получает сигнал и широковещательно транслирует его каждому из скрытых нейронов 
   2. > Каждый срктый нейрон Z вычислает результат активационной функции и рассылает свой сигнал zj всем выходным нейронам
   3. > Каждый выходной нейрон Yk вычисляет результат своей активационной функции yk и это фактически может считаться выходом сети
   4. > В процессе обучения каждый нейрон на выходе сети сравнивает вычисленное значение yk предоставленным целевым значением tk из обучающей выборки и определяет соответствующее знаение ошибки для каждого входного шаблона. На основании этой ошибки вычисляется СИГМАk, которая используется при распространении ошибки от выходных нейронов до нейронов предыдущего, то есть скрытого слоя, а также при изменениии весов связей. После того как все СИГМА определены происходит одновременная корретировка весов всех связей. 
2. Обратное распространение ошибки
3. Коректировка весов

# Алгоритм
0. Инициализация весов и смещений
   > рекомн. случайные небольшие значения. выбор начальных весов оказывает влияние на то сумеет ли сеть достичь минимума ошибки и насколько быстро этот процесс будет происходить. 
1. До тех пор пока условие прекращения работы алгоритма неверно выполнять шаги с 2 по 9. 
   > Условие прекращение - достижение минимума величины ошибки. Обучающую выборку делят на несколько частей. 
2. Для каждой пары {Данные, Целевое значение} выполняются шаги с 3 по 8(распространение данных от входов к выходам). 
3. Каждый входной нейрон xi(i=1,2,3,4..n) отправляет полученный сигнал всем нейронам в следующем слое (скрытым)
4. Скрытый нейрон Zj (j = 1,2,3..p) суммирует взвешенные входящие сигналы по формуле выше, применяет активавационную функцию и передает результат следующему слою (выходному) (см слайд 11 презентации [Схемы](https://github.com/SofiFairyTell/labwork_2021/blob/f8fd85a38d58c375844a49537ca698e513cc25f7/Моделирование систем_/Лекции/Схемы.pptx):)
5. Каждый выходной нейрон yk сумминрует взвешеныне выходящие сигналы и применяетс Активационную функцию вычисляя выходной сигнал (слайд 12)
6. Каждый нейрон yk получает целевое значение и вычисляет ошибку. Вычисляется величина, на которую изменится вес связи. Параметр альфа характеризует скорость обучения. Каждый нейрон вычисляет сигма, смещение. После этого отправляет величину сигмаk предыдущему слою (обратное распространение ошибки)
7. Каждый скрытый нейон суммирует входящие ошибки от нейронов в последующем слое и вычисляет величину ошибки умножая полученное значение на полученное от активационной функции. После этого определяет на какую величину изменится вес связи и смещение. 
8. Изменение весов. Каждый выходной нейрон изменяет веса своих связей и каждый скрытый нейрон изменяет свои смещения и вес своих связей. Прибавляем величину корректировки, которые мы вычислили на предыдущем шаге. 
9. Проверка условия прекрашения работы алгоритма: возможны два варианта
   - Достижение суммарной квадратичной ошибкой результата на выходе сети предустановленного заранее минимума
   - Выполненеи определенного количества итераций алгоритма

В основе алгоритма лежит метод градиентного спуска. В зависимости от знака градиент функции (в данном случае значение функции это ошибка, а параметры это веса связей в сети) дает направление в котором значение функции возрастает стремительно. 

# Архитектуры

1. Perceptron - однослойная
2. Feed Forward - сеть прямого распространения. Не образуются циклы. Каждый нейрон одного слоя связан с каждым нейроном на следующем слое. Это полносвязные сети. Увеличение числа слоев делает из нее сеть прямого распространения. Применются для сжатия данных, распознования речи и т.д. 
3. Сеть Радиальных базисных функций. Архитектура аналогична 2. В качестве функции активации используется радиальная базисная функция. Радиальная - любая вещественная функция, значение которой зависит только от расстояния до начала координат или от расстояния от другой точки называемой центром. Чаще используется для задач Аппроксимации. 
4. Рекуррентные нейронные сети обладает реккуретыным состояние приобретенном при обработке предущим элементам последовательности. Например на основе предыдущих слов узнать следующее в предложении. Такие сети имеют внутренние циклы (петли). Поэтому такие сети эффективны для распознавания рукописного текста или речи. 
5. Двунаправленные рекуррентные сети
6. LSTM - при большом объеме данных обычные реккурентые нейронные сети становятся непригодными для использования. Так как запоминают последнюю пригодную ифнормацию и забывают об информации полученной давным давно. 
7. Сверточные нейронные сети. Для распознавания объектов, изображений. 
8. Генеративные состязательные сети. Умеют генерировать данные не отличимые от исходных. 

# Эволюциоонные модели

Сначала создается множество случайно сформированных объектов с заданной структурой - популяция объектов и функция, определяющая близость объектов к истинному решению, называемая функцией цены. 
Работают по общей схеме: 
1. Определяется цена объектов в популяция
2. С учетом цены и привнесении элемента случайности создаются объекты для популяции следующей итерации. 
3. Данный процесс повторяется либо до получения решения либо до окончания времени отведенного на решение. 
популяция имеет "память" - в ней накапливаются лучшие результаты предыдущих итераций и этим ЭМ отличаются от других методов случайного поиска. 
В создании нового объекта популяции обычно участвуют два существующих объекта от каждого из которых новый объект отбирает часть свойств. Это __скрещивание__ или __crossover__ . Объекты подвергаются мутации (случаное Изменение)
Иногда используется т.н. стратегия элитизма при которой несколько лучших особей переходят в следующее поколение без измений не участвуя в __crossover__  и отборе. 

Алгоритм состоит из шагов:
1. Задается структура объектов, функция цены и условие останова. 
2. Создается популяция объектов P. 
3. С помощью функции цены из P выбирается множество лучших объектов
4. Из выбранных объектов создаются новые - претенденты на попадание в следующую популяцию
5. Образование новой P из полученных на шаге 4 объектов
6. Из объектов выбирается тот что с большей ценой. Это и есть искомое решение. 

# Причины распространения эволюционных вычислений

1. Показали свою эффективность
2. Высокий параллелизм

# Сферы применения

1. Автомтизация  решения оптимизационных задач науки и техники, те которые для MAX и MIN ищут для некоторой целевой функции на множестве ограничений. 
2. Изучение и моделирование процессов естественной эволюции

Типичными представителями эволюционных вычислений являются генетические алгоритмы. 

# Особенности генетических алгоритмов

1. Используют не непосредственно параметры задач а их закодированный вид. 
2. Ведут поиск который исходит не из единственнной точки а из полной популяции ( то есть множества точек)
3. Используют только функцию оценки и никакой другой вспомогательной информации . Например не нужно выясилять производные
4. Применяются вероятностные а не детерменированные правила выбора. 
5. Выполняется одновременный анализ различных областйе пространства решений

# Преимущества генетических алгоритмов

1. В них легко внедрить новые операторы
2. Простота организации паралеллельных вычислений
3. Независимость от вида функции, включая поддержку неаналитического задания функции

# Бинарные генетические алгоритмы. Постановка задач

(слайд 22)
Задана функция D (x1...xn). Допустим ищем экстремумы. тогда x будем рассматривать как организм (особь) с указанными характеристиками 
Тогда D будет интерпретирована как характеристика приспособленности (выживаемости организма) с заданными свойствами поэтому она названа функцией приспособенности (fitness- функция)

Создадим набор разных векторов x=(x1..xn) (особей) которые образуют популяцию и организуем эволюционный процесс  в котором особи будут совершенствоваться от поколения к поколению то есть повышать функцию приспособленности. 

Особи с низким уровнеи приспособленности "погибают", то есть удаляются из популяции, в результате эволюционного процесса выделяются лучшие особи. То есть те для которых наша функции имеет наивысшее значение при поике экстремумов. 

Для реализации такого процесса было предпложено: по аналогии с хромосомой живого организма необходимо представить наш вектор x в виде линейной структуры - цепочки бинарных символов. 
Для этого каждая xi кодируется с заданной точностью двоичным числом с числом разрадов li. 

Эта бинарная цепочка в генетических алгоритмах также называется хромосомой. 

Для генетических алгоритамх используется __код Грея__  

Пусть первое поколение состоит из n-организмов. с характеристиками хромосом (слайд 26):

Для организации эволюционного поиска применяются следующие процедуры:

1. Репродукция (оператор выбора родителей)
2. Кроссинговер (рекомбинация, воспроизведение)
3. Селекция (оператор отбора особей в новую популяцию)
4. Мутация 

# # Операторы выбора родителей:

1. Панмиксия - случайный выбор родителя
2. Инбридинг - первый родитель получается случайным образом. Второй - член популцяии ближайший к первомв родителю. Ближайши - через минимальное расстояние Хэмминга. 
3. Оутбридинг - также используется сходство особей. Второй родитель наименее похож на первого родителя.. 

2 и 3 бывает генотипным и фенотипным. 
В случае 1 сверяется похожесть самих особей. А в слуае 2 измеряется схожесть не самих особей, а функций приспособленности. 

После отбора родителей проводим процедеру рекомбинации (скрещивания или воспроизведения). 

1. Одноточечный кроссинговер - слайд 28
2. Двухточечный кроссинговер (вообще в многоточечном кроссинговере) хромосомы рассматриваются как циклы, которые формируются соединением концов линейной хромосомы вместе. Для замена сегмента одного цикла сегментом другого цикла требуется выбор двух точек разрыва(слайд 29)
3. Мнотогочечный кроссинговер - выбираем m-точек разреза. Точки разреза выбираются случайно без повторений и сортируются в порядке возрастания. Пример слайд 30. Участок  от первого бита по первой точки до первой точки разреза в обмене не участвует. 
4. Однородный кроссинговер - в данном способе создается маска особи, которая имеет ту же длину что и скрещивающиеся особи. Биты этой маски генерируются случайным образом. Слайд 31
5. Триадный кроссинговер - отличается от однородного тем, что после отбора пары родителей из остальных членов популяции случайным образом выбирается особь, которая в дальнейшем используется в качестве маски. Далее 10% генов маски мутируют. Затем гены первого родителя сравниваются с генами маски. Если гены одинаковы, то они передаются первому потомку. В противном случае на соотвествующие позиции хромосомы потомков переходят гены второго родителя. Генотип второго потомка отличается от генотипа первого генотипа тем, что на тех позициях, где у первого потомка стоят гены первого родителя, у второго потомка стоят гены второго родителя и наоборот. 
6. Перетасовочный кроссинговер - в данном алгоритме особи отобранные для кроссинговера случайным образом обмениваются генами. Затем выбирают точку для одноточечного кроссинговера 

